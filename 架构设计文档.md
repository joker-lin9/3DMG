# 系统架构设计文档
本作为独立作品，个人分工占比100%。
作品设计原因等产品相关内容见 [./产品设计文档.md](./产品设计文档.md)


## 1. **系统概述**

本系统包含三个主要组成部分：
- **本地模型的部署与调用**：使用两种不同的模型来生成3D内容，分别是 `Hunyuan3D-Shape-v2-1` 用于几何模型生成，`Hunyuan3D-Paint-v2-1` 用于纹理生成。
- **后端**：作为前端与模型之间的桥梁，接收前端用户的交互数据，将数据传递给模型，并将生成的结果返回给前端展示。后端同时管理任务队列、模型调用及状态更新。
- **前端**：由两大页面组成，一是3D模型生成页面（白模生成），二是文生图生成页面。负责用户交互和结果展示。

## 2. **系统架构组成**

### 2.1 **前端 - Web 界面**
前端包含两个主要页面：
1. **白模生成器（3D模型生成）**：
   - 用户上传图片，生成3D白模。
   - 用户可设置推理步数等参数。
   - 生成过程中会显示进度条。
   - 完成后提供 `.glb` 格式的下载链接。

   相关 HTML（来自 `i23D.html`）：
   - 提供图像上传和进度可视化功能。
   - 向后端发送请求（`/shape/`）触发模型生成。
   - 使用 `<model-viewer>` 标签展示3D模型。

2. **文生图生成器（T2I）**：
   - 用户输入绘画风格和多个主体对象（描述）。
   - 后端调用外部API（阿里云 DashScope 服务）生成图像。
   - 展示生成结果并提供下载链接。

   相关 HTML（来自 `t2i.html`）：
   - 处理用户输入的风格和主体。
   - 向后端发送请求（`/t2i/`）生成图像。
   - 提供预览和下载选项。

### 2.2 **后端 - Flask API**
后端使用 Flask 实现，提供两个主要的 API 路由：
1. **Shape Model API（3D模型生成）** (`/shape/`):
   - 接受来自前端的 base64 编码图像和推理步数。
   - 调用 **Hunyuan3DDiTFlowMatchingPipeline** 生成3D几何模型，并解码为 `.glb` 格式。
   - 提供通过 SSE 或轮询获取进度和任务状态的功能。
   - 生成完成后返回 `.glb` 文件。

   相关代码（来自 `shape_API.py`）：
   - 初始化模型并管理任务状态。
   - 使用线程进行模型推理，并更新任务状态。

2. **Text-to-Image API（T2I）** (`/t2i/`):
   - 接受用户输入的风格和主体。
   - 调用阿里云的 API 进行文生图生成。
   - 提供通过 SSE 或轮询获取进度和任务状态的功能。
   - 生成完成后，提供图像文件进行下载。

   相关代码（来自 `t2i_API.py`）：
   - 向阿里云服务发送生成请求，查询生成状态。
   - 管理任务状态并向前端返回图像结果。

### 2.3 **模型部署**
- **本地模型**：
  - `Hunyuan3D-Shape-v2-1` 用于生成几何模型（3.3B参数）。
  - `Hunyuan3D-Paint-v2-1` 用于生成纹理（2B参数）。
  - 这些模型通过 PyTorch 和其他库在本地部署，支持 GPU 加速。

- **外部 API**：
  - **阿里云 DashScope** 用于文生图生成。此 API 支持异步任务，前端提交文本描述后，后端通过调用该 API 来生成图像。

### 2.4 **模型调用与工作流**
- **3D模型生成** (`/shape/` 接口)：
  1. 用户上传图像。
  2. 前端将图像以 base64 格式发送至后端。
  3. 后端启动任务，调用本地 `Hunyuan3D-Shape-v2-1` 模型生成3D几何模型。
  4. 通过 SSE 或轮询获取进度并展示给用户。
  5. 完成后返回 `.glb` 格式的文件，供用户下载。

- **文生图生成** (`/t2i/` 接口)：
  1. 用户提供风格和主体对象（文本描述）。
  2. 前端将数据发送至后端。
  3. 后端创建新任务，并向阿里云 DashScope API 提交生成请求。
  4. 通过 SSE 或轮询获取任务进度，并将图像结果返回给用户。

### 2.5 **部署与托管**
- **后端服务**：后端使用 `Flask` 和 `Waitress` 部署。`shape_API.py` 监听 5013 端口处理 3D 模型生成请求，`t2i_API.py` 监听 5023 端口处理文生图生成请求。
  - 使用 `shape_run.py` 和 `t2i_run.py` 启动各自的服务。

  示例：
  ```bash
  python shape_run.py  # 启动 3D 模型生成服务，监听 5013 端口
  python t2i_run.py    # 启动文生图生成服务，监听 5023 端口

### 2.6 **API 流程**

* **文生图 API (T2I)**：

  1. 向 `/t2i/` 发送 POST 请求，触发图像生成任务。
  2. 通过 `/t2i/progress/{job_id}` 查询任务进度。
  3. 通过 `/t2i/result/{job_id}/{index}` 获取生成的图像。

* **Shape 模型 API**：

  1. 向 `/shape/` 发送 POST 请求，启动3D模型生成任务。
  2. 通过 `/progress/{job_id}` 查询任务进度。
  3. 通过 `/result/{job_id}` 获取生成的 `.glb` 文件。

## 3. **提示词优化与任务分解**

### 3.1 **提示词优化**

为了更好地生成适用于3D建模的图像，特别是在文生图生成过程中，我进行了提示词的优化。主要优化措施如下：

* **背景简化**：通过优化提示词，要求生成的图像具有简单的背景，这样可以避免复杂的背景干扰模型生成。
* **前景与背景的对比**：通过优化提示词，让前景与背景之间有明显的对比，从而更好地为后续的3D建模提供清晰的素材。

这种优化有助于确保生成的图像符合生成3D素材的要求，提高了最终模型的质量。

### 3.2 **任务分解与试错策略**

通过图生3D模型或文生3D模型，通常需要大量的试错过程，抛弃很多生成的无法使用的模型，而3D模型的生成本身非常消耗算力。因此，我认为应该将任务进行合理的分解：

1. **图像生成阶段**：首先使用优化后的提示词生成用户可以接受的图像，并筛选出适合用作3D建模素材的图像。这一步骤有效避免了不必要的计算资源浪费。
2. **3D建模阶段**：对经过筛选的图像进行建模，生成3D几何模型。此时可以通过不断的迭代优化模型，直到得到用户满意的3D模型。
3. **纹理生成阶段**：在3D建模完成后，使用 `Hunyuan3D-Paint-v2-1` 模型生成相应的纹理，进一步提升3D模型的细节和真实感。（模型已经部署，但由于时间限制，未完全实现）

### 3.3 **系统效率优化**

通过将任务分解成图像生成、3D建模和纹理生成三个阶段，可以有效减少不必要的计算浪费，同时确保每个阶段的输出都符合最终目标。这样，用户在体验过程中也能得到更高效和精确的结果。

## 4. **错误处理与日志**

* 后端包含错误处理机制，用于捕获并报告模型生成失败或 API 调用失败的情况。
* 日志用于调试和排错，尤其是在追踪任务进度时。

## 5. **潜在改进**

* **进度反馈**：为前端增加更详细的进度反馈，显示每个步骤的进度条。
* **扩展性**：考虑使用多实例分布式后端来处理大规模请求，提高系统的并发处理能力。

---

